{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score, f1_score, recall_score, precision_score, roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sheet FX SPOT\n",
      "Reading sheet ATM VOLS\n",
      "Reading sheet 3M 25D RR\n",
      "Reading sheet 3M DEPOSIT RATES\n",
      "Reading sheet 10Y YIELD\n",
      "Reading sheet EQUITY INDICES\n",
      "Reading sheet COMDTY\n",
      "Reading sheet CREDIT SPREADS\n",
      "Reading sheet IMM POSITIONING\n",
      "Reading sheet JPM EASI\n"
     ]
    }
   ],
   "source": [
    "days_in_month = 22\n",
    "days_in_week = 5\n",
    "days_in_year = 252\n",
    "    \n",
    "def getData():\n",
    "    \"\"\"\n",
    "     Reads all the data from the Data file and constructs df_main which holds all the predictors\n",
    "     input: nothing - Make sure you have the .xlsx file in the same folder as this .py file\n",
    "     output: \n",
    "         df_main- contains all the predictors\n",
    "         df_spot- Spot price for all the currencies\n",
    "         df_eurfwd- 1M EUR FWD rates\n",
    "         df_Implied_vols- ATM Implied Volatilities for all the FX pairs\n",
    "         df_deporates- 3M deposit rates for the given currencies\n",
    "         df_realized_vol - 2 month realized vols for all the currencies in df_spot\n",
    "    \"\"\"    \n",
    "    sheetname       = [\"FX SPOT\", \"ATM VOLS\",\"3M 25D RR\", \"3M DEPOSIT RATES\",\"10Y YIELD\",\"EQUITY INDICES\",\"COMDTY\",\"CREDIT SPREADS\",\"IMM POSITIONING\"]\n",
    "    levels          = [\"ATM VOLS\", \"3M 25D RR\"]\n",
    "    filename        = \"DataTables.xlsx\"\n",
    "    \n",
    "    # Dataframe of Spot prices\n",
    "    df_spot         = pd.read_excel(filename,\"FX SPOT\",parse_dates=True, index_col='Dates')\n",
    "    df_spot         = df_spot[df_spot.index.dayofweek < days_in_week]\n",
    "    \n",
    "    # Dataframe of EURUSD 1M forward rates prices\n",
    "    df_eurfwd       = pd.read_excel(filename,\"1M EUR FWD\",parse_dates=True, index_col='Dates')\n",
    "    df_eurfwd       = df_eurfwd[df_eurfwd.index.dayofweek < days_in_week]\n",
    "    \n",
    "    # Dataframe of 1M Implied Volatilities\n",
    "    df_Implied_vols = pd.read_excel(filename,\"ATM VOLS\",parse_dates=True, index_col='Dates')\n",
    "    df_Implied_vols = df_Implied_vols[df_Implied_vols.index.dayofweek < days_in_week]\n",
    "    \n",
    "    # Dataframe of Deposit rates\n",
    "    df_deporates    = pd.read_excel(filename,\"3M DEPOSIT RATES\",parse_dates=True, index_col='Dates')\n",
    "    df_deporates    = df_deporates[df_deporates.index.dayofweek < days_in_week]\n",
    "    \n",
    "    #df_main holds all the data - predictors all 373 of them\n",
    "    df_main         = pd.DataFrame(index = df_spot.index)\n",
    "    \n",
    "    # Calculating spot returns to be further used in calculating 2M realized volatilities\n",
    "    df_returns              = df_spot.pct_change()\n",
    "    df_realized_vol         = pd.DataFrame(df_returns.rolling(window = days_in_month*2).std()*np.sqrt(days_in_year), index = df_spot.index, columns = df_spot.columns).shift(1)\n",
    "    df_realized_vol.columns = [str(col) + 'Vol2M' for col in df_realized_vol.columns]\n",
    "    \n",
    "    \n",
    "    # Calculating 1W change in realized Volatilities\n",
    "    df_1W_vol_per_change            = (df_realized_vol.astype(float) / df_realized_vol.astype(float).shift(days_in_week) - 1) \n",
    "    df_1W_vol_per_change.columns    = [str(col) + '1W' for col in df_1W_vol_per_change.columns]\n",
    "    \n",
    "    \n",
    "    # Calculating 1month change in realized Volatilities\n",
    "    df_1M_vol_per_change            = (df_realized_vol.astype(float) / df_realized_vol.astype(float).shift(days_in_month) - 1) \n",
    "    df_1M_vol_per_change.columns    = [str(col) + '1M' for col in df_1M_vol_per_change.columns]\n",
    "    \n",
    "    \n",
    "    # Adding the Volatilite, 1W change in vols and 1M change in realized vols to the master dataframe\n",
    "    df_main     =   df_main.join(df_realized_vol)\n",
    "    df_main     =   df_main.join(df_1W_vol_per_change)\n",
    "    df_main     =   df_main.join(df_1M_vol_per_change)\n",
    "    \n",
    "    \n",
    "    #Looping through all the sheets and individual predictors to calculate 1week and 1month change \n",
    "    #and joining them in the Master dataframe - df_main\n",
    "    for sheet in sheetname:\n",
    "        df      =       pd.DataFrame()\n",
    "        df      =       pd.read_excel(filename,sheet,parse_dates=True, index_col='Dates')\n",
    "        df      =       df[df.index.dayofweek < days_in_week] # removing all the weekend dates from the dataset\n",
    "    \n",
    "        if sheet in levels:\n",
    "            df_main     =       df_main.join(df.shift(1))\n",
    "        \n",
    "        print(\"Reading sheet\", sheet)\n",
    "        df_1W_per_change            = (df.astype(float) / df.astype(float).shift(days_in_week) - 1) \n",
    "        df_1W_per_change.columns    = [str(col) + '1W' for col in df_1W_per_change.columns]\n",
    "        df_1M_per_change            = (df.astype(float) / df.astype(float).shift(days_in_month) - 1) \n",
    "        df_1M_per_change.columns    = [str(col) + '1M' for col in df_1M_per_change.columns]\n",
    "        \n",
    "        df_main         =   df_main.join(df_1W_per_change.shift(1))\n",
    "        df_main         =   df_main.join(df_1M_per_change.shift(1))\n",
    "        \n",
    "    print(\"Reading sheet JPM EASI\")\n",
    "    df_easi         =   pd.read_excel(filename,\"JPM EASI\",parse_dates=True, index_col='Dates')\n",
    "    df_easi         =   df_easi[df_easi.index.dayofweek < days_in_week]\n",
    "    df_easi.fillna(0, inplace = True)\n",
    "    \n",
    "    # JPM EASI is an index value between -100 to +100, so we have divided by total range (200) to find out change in 1W and 1M\n",
    "    df_easi_1W          = (df_easi.astype(float) - df_easi.astype(float).shift(days_in_week))/ 200\n",
    "    df_easi_1W.columns  = [str(col) + '1W' for col in df_easi_1W.columns]\n",
    "    df_easi_1M          = (df_easi.astype(float) - df_easi.astype(float).shift(days_in_month))/200 \n",
    "    df_easi_1M.columns  = [str(col) + '1M' for col in df_easi_1M.columns]\n",
    "    df_main             = df_main.join(df_easi_1W.shift(1))\n",
    "    df_main             = df_main.join(df_easi_1M.shift(1))\n",
    "    \n",
    "    return df_main, df_spot, df_eurfwd, df_Implied_vols, df_deporates, df_realized_vol\n",
    "\n",
    "df_main, _, _, _, _, _ = getData()\n",
    "df_main = df_main.replace([np.inf, -np.inf], np.nan) # replace infinity with nan\n",
    "df_main = df_main.fillna(0)\n",
    "df_main['date'] = df_main.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_returns_all(cmdata):\n",
    "    retdata = copy.deepcopy(cmdata)\n",
    "    cols = [x for x in list(cmdata.columns) if x != 'date']\n",
    "    retdata[cols] = (cmdata[cols].shift(1)/cmdata[cols].shift(0) - 1) > 0\n",
    "    retdata[[x+'_1d' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-1) - 1) \n",
    "    retdata[[x+'_1w' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-days_in_week) - 1) \n",
    "    retdata[[x+'_1m' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-days_in_month) - 1)\n",
    "    retdata[[x+'_1y' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-days_in_year) - 1) \n",
    "    '''\n",
    "    retdata = retdata.dropna()\n",
    "    def bin_targets(x):\n",
    "        if x<0: return -1\n",
    "        if x>0: return 1\n",
    "        return 0\n",
    "\n",
    "    for col in cols:\n",
    "        retdata[col]=retdata[col].apply(bin_targets)\n",
    "    '''\n",
    "    return retdata.dropna().reset_index(drop=True)\n",
    "\n",
    "def get_returns_overall(cmdata):\n",
    "    retdata = pd.DataFrame({'date':cmdata.date, 'returns':cmdata.sum(axis=1)})\n",
    "    cols = [x for x in list(cmdata.columns) if x != 'date']\n",
    "    retdata['returns'] = (retdata['returns'].shift(1)/retdata['returns'].shift(0) - 1) > 0\n",
    "    retdata[[x+'_1d' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-1) - 1) \n",
    "    retdata[[x+'_1w' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-days_in_week) - 1) \n",
    "    retdata[[x+'_1m' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-days_in_month) - 1)\n",
    "    retdata[[x+'_1y' for x in cols]] = (cmdata[cols].shift(0)/cmdata[cols].shift(-days_in_year) - 1) \n",
    "    return retdata.dropna().reset_index(drop=True)\n",
    "\n",
    "# True = Up\n",
    "# False = Down or same value/0% return\n",
    "cmdata = pd.read_excel('Commodity Data.xlsx')\n",
    "#cmdata = cmdata.dropna()\n",
    "cmdata=cmdata.fillna(0)\n",
    "ret_df = get_returns_overall(cmdata)\n",
    "#ret_df = get_returns_all(cmdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintestsplit(X,Y,split):\n",
    "    \"\"\"\n",
    "     Splits the data set into training & Quarantine/test set from the given dataframes X & Y\n",
    "     input: X & Y Dataframes as formed in the main, \n",
    "            split - the % split between training & test/quarantine dataset\n",
    "     output: trainX,testX, trainY, testY\n",
    "\n",
    "    \"\"\"\n",
    "    trainX      =   X.iloc[0:round(split*X.shape[0]),:]\n",
    "    testX       =   X.iloc[round(split*X.shape[0]):,:]\n",
    "    trainY      =   Y.iloc[0:round(split*Y.shape[0]),:]\n",
    "    testY       =   Y.iloc[round(split*Y.shape[0]):,:]\n",
    "    \n",
    "    return trainX,testX, trainY, testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeHyperParameters(train_X,train_Y, model, cv_folds):\n",
    "    \"\"\"\n",
    "     Optimize the models Hyper Parameter.\n",
    "     For simplicity we have used only one Hyperparameter for the model to regularize\n",
    "     input: training and test data set in dataframe format, the algorithm to be applied and the number of folds for cross validation\n",
    "     output: index of the tuned HyperParameter,training accuracy & test accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    tscv = TimeSeriesSplit(n_splits=cv_folds)\n",
    "    acctrain    = []\n",
    "    acctest     = []\n",
    "    error       = []\n",
    "\n",
    "    # Iterate over all the 10 folds for each parameter     \n",
    "    for train, test in tscv.split(train_X,train_Y):\n",
    "\n",
    "        model.fit(train_X[train], train_Y[train])\n",
    "        pred    =   model.predict(train_X[test])\n",
    "\n",
    "        # Append the scores to the respective training and test scores list\n",
    "        acctrain.append(model.score(train_X[train], train_Y[train]))\n",
    "        acctest.append(model.score(train_X[test], train_Y[test]))\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy   = np.mean(acctrain)\n",
    "\n",
    "    #Compute accuracy on the Cross Validation set\n",
    "    test_accuracy    = np.mean(acctest)\n",
    "\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Matching Dates: 2615\n"
     ]
    }
   ],
   "source": [
    "#Overall\n",
    "ret_df = get_returns_overall(cmdata)\n",
    "full_df=pd.merge(left=ret_df, right=df_main, left_on='date', right_on='date')\n",
    "full_df = full_df[full_df[[x for x in df_main.columns if x!='date']].sum(axis=1)!=0] # get rid of 0-value features\n",
    "print(\"Total Matching Dates: {}\".format((len(full_df))))\n",
    "X = full_df[[x for x in full_df.columns if x not in ['date', 'returns']]]\n",
    "Y = full_df[['date','returns']]\n",
    "trainX, testX, trainY, testY = traintestsplit(X, Y, 0.8)\n",
    "trainX, testX, trainY, testY = np.array(trainX), np.array(testX), np.array(trainY['returns']), np.array(testY['returns'])\n",
    "\n",
    "trainY_ = trainY\n",
    "testY_ = testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specific Commodity\n",
    "\n",
    "#ret_df = get_returns_all(cmdata)\n",
    "#full_df=pd.merge(left=ret_df, right=df_main, left_on='date', right_on='date')\n",
    "#full_df = full_df[full_df[[x for x in df_main.columns if x!='date']].sum(axis=1)!=0] # get rid of 0-value features\n",
    "#print(\"Total Matching Dates: {}\".format((len(full_df))))\n",
    "#X = full_df[[x for x in full_df.columns if x not in cmdata.columns]]\n",
    "#Y = full_df[[x for x in cmdata.columns if x!='date']]\n",
    "#trainX, testX, trainY, testY = traintestsplit(X, Y, 0.8)\n",
    "#trainX, testX, trainY, testY = np.array(trainX), np.array(testX), np.array(trainY), np.array(testY)\n",
    "\n",
    "### If using specific commodity\n",
    "#commodity_idx = 0 # 0 = wheat\n",
    "#trainY_ = trainY[:,commodity_idx]\n",
    "#testY_ = testY[:,commodity_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(trainX)\n",
    "trainX_pca = pca.transform(trainX)\n",
    "testX_pca = pca.transform(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = MLPClassifier(hidden_layer_sizes=(32,16,8,4,2))\n",
    "clf2 = XGBClassifier(max_depth=20)\n",
    "clf3 = LogisticRegression()\n",
    "clf4 = LinearSVC(C=0.1)\n",
    "clf5 = RandomForestClassifier(max_depth=20)\n",
    "clf6 = DecisionTreeClassifier(max_depth=20)\n",
    "clf7 = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.761\t CV Accuracy: 0.531\n"
     ]
    }
   ],
   "source": [
    "# First train the neural network onto the data then evalulate the test performance\n",
    "cv_res1 = optimizeHyperParameters(trainX, trainY_, clf1, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res1[0], cv_res1[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4397705544933078\n",
      "0.5684830633284241\n",
      "0.8464912280701754\n",
      "0.4279379157427938\n",
      "0.4859574784418674\n",
      "[[ 37 258]\n",
      " [ 35 193]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.13      0.20       295\n",
      "        True       0.43      0.85      0.57       228\n",
      "\n",
      "   micro avg       0.44      0.44      0.44       523\n",
      "   macro avg       0.47      0.49      0.39       523\n",
      "weighted avg       0.48      0.44      0.36       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1.fit(trainX, trainY_)\n",
    "preds1 = clf1.predict(testX)\n",
    "print(accuracy_score(testY_, preds1))\n",
    "print(f1_score(testY_, preds1))\n",
    "print(recall_score(testY_, preds1))\n",
    "print(precision_score(testY_, preds1))\n",
    "print(roc_auc_score(testY_, preds1))\n",
    "print(confusion_matrix(testY_, preds1))\n",
    "print(classification_report(testY_, preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:1.000\t CV Accuracy: 0.561\n"
     ]
    }
   ],
   "source": [
    "# The train XGBoost onto the data then evalulate the test performance\n",
    "cv_res2 = optimizeHyperParameters(trainX, trainY_, clf2, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res2[0], cv_res2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5487571701720841\n",
      "0.48471615720524025\n",
      "0.4868421052631579\n",
      "0.4826086956521739\n",
      "0.5417261373773417\n",
      "[[176 119]\n",
      " [117 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.60      0.60       295\n",
      "        True       0.48      0.49      0.48       228\n",
      "\n",
      "   micro avg       0.55      0.55      0.55       523\n",
      "   macro avg       0.54      0.54      0.54       523\n",
      "weighted avg       0.55      0.55      0.55       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2.fit(trainX, trainY_)\n",
    "preds2 = clf2.predict(testX)\n",
    "print(accuracy_score(testY_, preds2))\n",
    "print(f1_score(testY_, preds2))\n",
    "print(recall_score(testY_, preds2))\n",
    "print(precision_score(testY_, preds2))\n",
    "print(roc_auc_score(testY_, preds2))\n",
    "print(confusion_matrix(testY_, preds2))\n",
    "print(classification_report(testY_, preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.728\t CV Accuracy: 0.506\n"
     ]
    }
   ],
   "source": [
    "# The train the Logistic Regression onto the data then evalulate the test performance\n",
    "cv_res3 = optimizeHyperParameters(trainX, trainY_, clf3, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res3[0], cv_res3[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4474187380497132\n",
      "0.5614567526555386\n",
      "0.8114035087719298\n",
      "0.42923433874709976\n",
      "0.48875260184359204\n",
      "[[ 49 246]\n",
      " [ 43 185]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      0.17      0.25       295\n",
      "        True       0.43      0.81      0.56       228\n",
      "\n",
      "   micro avg       0.45      0.45      0.45       523\n",
      "   macro avg       0.48      0.49      0.41       523\n",
      "weighted avg       0.49      0.45      0.39       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf3.fit(trainX, trainY_)\n",
    "preds3 = clf3.predict(testX)\n",
    "print(accuracy_score(testY_, preds3))\n",
    "print(f1_score(testY_, preds3))\n",
    "print(recall_score(testY_, preds3))\n",
    "print(precision_score(testY_, preds3))\n",
    "print(roc_auc_score(testY_, preds3))\n",
    "print(confusion_matrix(testY_, preds3))\n",
    "print(classification_report(testY_, preds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.630\t CV Accuracy: 0.503\n"
     ]
    }
   ],
   "source": [
    "# The train the Linear SVC onto the data then evalulate the test performance\n",
    "cv_res4 = optimizeHyperParameters(trainX, trainY_, clf4, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res4[0], cv_res4[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5009560229445507\n",
      "0.4727272727272727\n",
      "0.5131578947368421\n",
      "0.43820224719101125\n",
      "0.5023416592328278\n",
      "[[145 150]\n",
      " [111 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.49      0.53       295\n",
      "        True       0.44      0.51      0.47       228\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       523\n",
      "   macro avg       0.50      0.50      0.50       523\n",
      "weighted avg       0.51      0.50      0.50       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf4.fit(trainX, trainY_)\n",
    "preds4 = clf4.predict(testX)\n",
    "print(accuracy_score(testY_, preds4))\n",
    "print(f1_score(testY_, preds4))\n",
    "print(recall_score(testY_, preds4))\n",
    "print(precision_score(testY_, preds4))\n",
    "print(roc_auc_score(testY_, preds4))\n",
    "print(confusion_matrix(testY_, preds4))\n",
    "print(classification_report(testY_, preds4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.984\t CV Accuracy: 0.505\n"
     ]
    }
   ],
   "source": [
    "# The train the Random Forest Classifier onto the data then evalulate the test performance\n",
    "cv_res5 = optimizeHyperParameters(trainX, trainY_, clf5, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res5[0], cv_res5[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5411089866156787\n",
      "0.4230769230769231\n",
      "0.38596491228070173\n",
      "0.46808510638297873\n",
      "0.523490930716622\n",
      "[[195 100]\n",
      " [140  88]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.58      0.66      0.62       295\n",
      "        True       0.47      0.39      0.42       228\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       523\n",
      "   macro avg       0.53      0.52      0.52       523\n",
      "weighted avg       0.53      0.54      0.53       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf5.fit(trainX, trainY_)\n",
    "preds5 = clf5.predict(testX)\n",
    "print(accuracy_score(testY_, preds5))\n",
    "print(f1_score(testY_, preds5))\n",
    "print(recall_score(testY_, preds5))\n",
    "print(precision_score(testY_, preds5))\n",
    "print(roc_auc_score(testY_, preds5))\n",
    "print(confusion_matrix(testY_, preds5))\n",
    "print(classification_report(testY_, preds5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:1.000\t CV Accuracy: 0.497\n"
     ]
    }
   ],
   "source": [
    "# The train the Deicision tree Classifier onto the data then evalulate the test performance\n",
    "cv_res6 = optimizeHyperParameters(trainX, trainY_, clf6, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res6[0], cv_res6[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5105162523900574\n",
      "0.43612334801762115\n",
      "0.4342105263157895\n",
      "0.43805309734513276\n",
      "0.5018510258697592\n",
      "[[168 127]\n",
      " [129  99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.57      0.57       295\n",
      "        True       0.44      0.43      0.44       228\n",
      "\n",
      "   micro avg       0.51      0.51      0.51       523\n",
      "   macro avg       0.50      0.50      0.50       523\n",
      "weighted avg       0.51      0.51      0.51       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf6.fit(trainX, trainY_)\n",
    "preds6 = clf6.predict(testX)\n",
    "print(accuracy_score(testY_, preds6))\n",
    "print(f1_score(testY_, preds6))\n",
    "print(recall_score(testY_, preds6))\n",
    "print(precision_score(testY_, preds6))\n",
    "print(roc_auc_score(testY_, preds6))\n",
    "print(confusion_matrix(testY_, preds6))\n",
    "print(classification_report(testY_, preds6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:0.625\t CV Accuracy: 0.518\n"
     ]
    }
   ],
   "source": [
    "# The train the K Nearest Neighbours Classifier onto the data then evalulate the test performance\n",
    "cv_res7 = optimizeHyperParameters(trainX, trainY_, clf7, 10)\n",
    "print(\"Training Accuracy:{:.03f}\\t CV Accuracy: {:.03f}\".format(cv_res7[0], cv_res7[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49521988527724664\n",
      "0.46987951807228917\n",
      "0.5131578947368421\n",
      "0.43333333333333335\n",
      "0.4972569134701159\n",
      "[[142 153]\n",
      " [111 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.48      0.52       295\n",
      "        True       0.43      0.51      0.47       228\n",
      "\n",
      "   micro avg       0.50      0.50      0.50       523\n",
      "   macro avg       0.50      0.50      0.49       523\n",
      "weighted avg       0.51      0.50      0.50       523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf7.fit(trainX, trainY_)\n",
    "preds7 = clf7.predict(testX)\n",
    "print(accuracy_score(testY_, preds7))\n",
    "print(f1_score(testY_, preds7))\n",
    "print(recall_score(testY_, preds7))\n",
    "print(precision_score(testY_, preds7))\n",
    "print(roc_auc_score(testY_, preds7))\n",
    "print(confusion_matrix(testY_, preds7))\n",
    "print(classification_report(testY_, preds7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
